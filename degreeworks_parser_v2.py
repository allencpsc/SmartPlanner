# Austin Lee 3/30/2023
# CPSC 4176 Project

from degree_extraction_container import DegreeExtractionContainer
from alias_module import get_latest_id
import re
from pypdf import PdfReader
from driver_fs_functions import *
import pickle

#james cbr stuff
import PDF_to_CBR_Formatter


# ========================================================================================================
# TODO: implement custom error handling/ exceptions
# TODO: create error report for the user

# Student information helper functions
# ========================================================================================================

# Gets the baccalaureate degrees pickle file generated by the CSU Public Data Parser.
def get_baccalaureate_degrees_pickle_file():
    file1 = get_source_path()
    file1 = get_source_relative_path(file1, "output_files/baccalaureate_degrees_dictionary.pickle")

    with open(file1, "rb") as f:
        obj = pickle.load(f)

    return obj

# Gets a student's name from the Degreeworks document.
def get_student_name(document_string):
    student_name = None
    working_string = document_string[document_string.find('Ellucian University ') + len('Ellucian University '):document_string.find('Student name')]
    student_name_match_obj = re.search(r'[a-zA-Z]+, [a-zA-Z]+ - ', working_string)

    if student_name_match_obj:
        student_name = student_name_match_obj.group()[:student_name_match_obj.group().find(' - ')]

    return student_name

# Gets a student's student number (CSU student ID) from a Degreeworks document
def get_student_number(document_string):
    student_number = None
    working_string = document_string[document_string.find('Ellucian University ') + len('Ellucian University '):document_string.find('Student name')]
    student_number_match_obj = re.search(r'\d{9}', working_string)

    if student_number_match_obj:
        student_number = student_number_match_obj.group()

    return student_number

# Gets a student's degree plan from a Degreeworks document
def get_degree_plan_name(document_string):
    degree_plan_name = ''
    raw_major = None
    aliased_major = None

    raw_track = None
    aliased_track = None

    working_string_match_obj = re.search(r'(?:Majors?)(.*?)(?:(?:Minors?|Program))', document_string)      
      
    if working_string_match_obj:
        working_string = working_string_match_obj.group(1).strip()

    majors_raw_strings_list = []
    major_dict = {}
    majors_dict = get_baccalaureate_degrees_pickle_file()
    if ',' in working_string:
        majors_raw_strings_list = working_string.split(',')
    else:
        majors_raw_strings_list.append(working_string)
    for i, major in enumerate(majors_raw_strings_list):
        if ' - ' in major:
            raw_major = major[:re.search(r'\s?-\s?', major).start()].strip()
            raw_track = major[re.search(r'\s?-\s?', major).end():].strip()
        else:
            raw_major = major
            raw_track = 'NONE'
        
        for key in majors_dict.keys():
            if raw_major in key:
                aliased_major = raw_major
                major_dict = {key: majors_dict[key]}
                break
        
        for key, value in major_dict.items():
            for string in value:
                if string.find(raw_track) != -1:
                    aliased_track = string
                else:
                    aliased_track = raw_track

        degree_plan_name += aliased_major + ' - ' + aliased_track
        
        if i < len(majors_raw_strings_list) - 1:
            degree_plan_name += ', '

    return degree_plan_name


#Gets number of electives needed for CBR input
def get_cpsc_elective_count(document_string):
    pass

# Gets a student's gpa from a Degreeworks document
def get_gpa(document_string):
    gpa = None

    gpa_chunk_match_obj = re.search(r'Overall\s?GPA\s?\d\.\d\d?', document_string)

    if gpa_chunk_match_obj:
        gpa_match_obj_str = re.search(r'\d\.\d\d?', gpa_chunk_match_obj.group()).group()
        
        if gpa_match_obj_str:
            try:
                float(gpa_match_obj_str)
                gpa = gpa_match_obj_str
            except:
                gpa = None

    return gpa

# Current/taken courses helper functions
# ========================================================================================================

# Searches a Degreeworks document for the first instance of an occurence of an item in a list of known
# backstops, then trims the document_string at that occurrence.
def trim_document_string(document_string):

    key_phrases = [
        'Fall Through',
        'Insufficient',
        'In-progress',
        'Over The Limit',
        'Split Credits',
        'Exceptions',
        'Notes'
    ]

    search_pattern = r'|'.join(re.escape(key_phrase) for key_phrase in key_phrases)
    match_obj = re.search(search_pattern, document_string)

    if match_obj:
        document_string = document_string[:match_obj.start()]

    return document_string

# Searches the Degreeworks document for all instances of current/taken courses by looking for any instance
# of a season/year block, then working backward to find the current/taken course.
def find_curr_taken_courses(document_string):
    taken_course_year_pairing = set() # The format of this is '{course} - {year}'

    document_string = trim_document_string(document_string)

    season_year_block_indices_list = list(reversed([(match.start(), match.end()) for match in re.finditer(r'(Spring|Fall|Summer)\s(Term|Semester)\s\d{4}', document_string)]))
    course_block_indices_list = list(reversed([(match.start(), match.end()) for match in re.finditer(r'([A-Z\*]{4} [0-9\*]{4}[A-Z]?)|([A-Z\*]{3} [0-9\*]{4})', document_string)]))
    number_of_course_blocks = len(course_block_indices_list)

    curr_taken_courses = []
    working_course_index = 0

    for season_year_block_start_index, season_year_block_end_index in season_year_block_indices_list:
        course_range = course_block_indices_list[working_course_index]
        
        while course_range[0] > season_year_block_start_index and working_course_index < number_of_course_blocks:
            working_course_index += 1
            course_range = course_block_indices_list[working_course_index]
        
        if working_course_index < number_of_course_blocks:
            course_number = document_string[course_range[0]:course_range[1]].strip()
            semester_year = document_string[season_year_block_start_index:season_year_block_end_index].strip()
            course_year_pairing = f'{course_number} - {semester_year}'
            
            if course_year_pairing not in taken_course_year_pairing:
                curr_taken_courses.append(course_number)
                taken_course_year_pairing.add(course_year_pairing)
    
    return curr_taken_courses

# Courses needed constuction string functions
# ========================================================================================================

# Gets the index of the first occurrence of an item from the list of known trimming phrases.
def get_index_of_first_ending_trim_phrase(document_string):
    first_ending_trim_phrase_index = -1

    key_phrases = [
        'Fall Through',
        'Insufficient',
        'In-progress',
        'Over The Limit',
        'Split Credits',
        'Exceptions',
        'Notes'
    ]

    search_pattern = r'|'.join(re.escape(key_phrase) for key_phrase in key_phrases)
    match_obj = re.search(search_pattern, document_string)
    
    if match_obj:
        first_ending_trim_phrase_index = match_obj.start()

    return first_ending_trim_phrase_index

# Splits the document string into chunks at each occurrence of the phrase 'Still needed:'
def split_into_still_needed_chunks(document_string):
    still_needed_chunks = []

    still_needed_chunk_starting_index = document_string.find('Still needed:')

    while still_needed_chunk_starting_index != -1:
        still_needed_chunk_ending_index = document_string.find('Still needed:', still_needed_chunk_starting_index + 1)
        
        if still_needed_chunk_ending_index != -1:
            still_needed_chunks.append(document_string[still_needed_chunk_starting_index:still_needed_chunk_ending_index])
            still_needed_chunk_starting_index = still_needed_chunk_ending_index
        else:
            still_needed_chunks.append(document_string[still_needed_chunk_starting_index:get_index_of_first_ending_trim_phrase(document_string)])
            break
    
    return still_needed_chunks

# Generates and returns a string of the simple deliverable courses in the Degreeworks document,
# with the format: (CPSC 1234,CPSC 1235)
def generate_simple_deliverables_string(document_string):
    logical_grouping_start_match_obj = re.search(r'Still needed:[\s\n]+Choose from \d{1,2} of the following:', document_string)
    
    if logical_grouping_start_match_obj:
        logical_grouping_start_index = logical_grouping_start_match_obj.start()
        remaining_document_string = document_string[logical_grouping_start_match_obj.end():]
        logical_grouping_end_match_obj = re.search(r'Still needed:', remaining_document_string)
        
        if logical_grouping_end_match_obj:
            document_string = document_string[:logical_grouping_start_index] + remaining_document_string[logical_grouping_end_match_obj.start():]
    
    still_needed_chunks = split_into_still_needed_chunks(document_string)
    
    deliverables_str = ''
    deliverables_list = []

    for chunk in still_needed_chunks:
        if not (re.search(r'1 Class in [A-Z]{4} \d{4}[A-Z@]?[\s\n]+or[\s\n]+',chunk)):
            if(match := re.search(r'1 Class in [A-Z]{4} \d{4}(?:[A-Z](?=[\s\n]|Ellucian))?', chunk)):
                deliverables_list.append(match.group())
    
    deliverables_str += '('

    for deliverable_index, deliverable in enumerate(deliverables_list):
        match = re.search(r'[A-Z]{4} \d{4}[A-Z]?', deliverable)
        if match:
            deliverables_str += get_latest_id(match.group())
        if deliverable_index < len(deliverables_list) - 1:
            deliverables_str += ','
    
    deliverables_str += ')\n\n'
    
    return deliverables_str

# Finds the ranges of all current/taken course blocks and removes these blocks from the 
# document string to prevent current/taken courses from being registered during searches for other 
# types of courses in the Degreeworks document.
def remove_all_curr_taken_courses(document_string):
    trimmed_string = trim_document_string(document_string)

    curr_taken_courses_removed_string = ''

    season_year_block_indices_list = list(reversed([(match.start(), match.end()) for match in re.finditer(r'(Spring|Fall|Summer)[\s\n](Term|Semester)\s\d{4}\n?', document_string)]))
    course_block_indices_list = list(reversed([(match.start(), match.end()) for match in re.finditer(r'([A-Z\*]{4} [0-9\*]{4}[A-Z]?)|([A-Z\*]{3} [0-9\*]{4})', document_string)]))
    number_of_course_blocks = len(course_block_indices_list)
    working_course_index = 0
    course_year_ranges = []
    
    for season_year_block_start_index, season_year_block_end_index in season_year_block_indices_list:
        course_range = course_block_indices_list[working_course_index]
        while course_range[0] > season_year_block_start_index and working_course_index < number_of_course_blocks:
            working_course_index += 1
            course_range = course_block_indices_list[working_course_index]
        if working_course_index < number_of_course_blocks:
            course_year_range = (course_range[0], season_year_block_end_index)
            course_year_ranges.append(course_year_range)
    
    curr_taken_courses_removed_string = ''
    prev_range_end_index = 0
    
    reversed_course_year_ranges = list(reversed(course_year_ranges))
    
    for range_index, range in enumerate(reversed_course_year_ranges):
        curr_taken_courses_removed_string += trimmed_string[prev_range_end_index:range[0]]
        prev_range_end_index = range[1]
    
    curr_taken_courses_removed_string += trimmed_string[prev_range_end_index:]
    
    return curr_taken_courses_removed_string

# Removes all 'Still needed:' chunks that do not contain a valid course block
def remove_no_course_still_needed_chunks(still_needed_chunks):
    comprehensive_letter_block_regex_pattern = r'(?:[A-Z]{4}|@)'
    comprehensive_number_block_regex_pattern = r'(?:\d{4}([@A-Z])?|\d@)'
    comprehensive_course_block_regex_pattern = f'{comprehensive_letter_block_regex_pattern}\s{{0,6}}{comprehensive_number_block_regex_pattern}'
    
    still_needed_chunks_all_non_complex_still_needed_chunks_removed_list = []

    for chunk in still_needed_chunks:
        match = None

        if (match := re.search(comprehensive_course_block_regex_pattern, chunk)):
            still_needed_chunks_all_non_complex_still_needed_chunks_removed_list.append(chunk)

    return still_needed_chunks_all_non_complex_still_needed_chunks_removed_list

# Removes all 'Still needed:' chunks that do not start with a valid course block
def remove_chunks_not_starting_with_course(still_needed_chunks):
    still_needed_chunks_starting_with_course_list = []

    for chunk in still_needed_chunks:
        if (match := re.search('Still needed:\s{0,3}(Choose from|(?:\d{1,2})\sCredit[s]? in|(?:\d{1,2})\sClass[es]? in)', chunk)):
            still_needed_chunks_starting_with_course_list.append(chunk)

    return still_needed_chunks_starting_with_course_list

# Removes 'Ellucian University' and student info (name, student ID) from all 'Still needed:' chunks
def remove_student_info(still_needed_chunks):
    still_needed_chunks_student_info_removed_list = []

    for chunk in still_needed_chunks:
        chunk.replace('\n','')

    for chunk in still_needed_chunks:
        if (match := re.search(r'Ellucian University\s{0,3}[a-zA-Z]+\s{0,2},\s{0,2}[a-zA-Z]+\s{0,2}-\s{0,2}\d{9}', chunk)):
            chunk = chunk.replace(match.group(), '')
            still_needed_chunks_student_info_removed_list.append(chunk)
        else:
            still_needed_chunks_student_info_removed_list.append(chunk)

    return still_needed_chunks_student_info_removed_list

# Removes all 'Satisfied by:' blocks from the 'Still needed:' chunks
def remove_satisfied_by_blocks(still_needed_chunks):
    still_needed_chunks_satisfied_by_removed_list = []

    for chunk in still_needed_chunks:
        if (match_list := re.findall(r'Satisfied by:\s{0,5}[a-zA-Z0-9]+\s{0,2}-\s{0,2}.+-', chunk)):
            for match in match_list:
                chunk = chunk.replace(match, '')

        still_needed_chunks_satisfied_by_removed_list.append(chunk)

    return still_needed_chunks_satisfied_by_removed_list

# Searches each 'Still needed:' chunk for the first occurrence of an instance of 'Area X', then removes
# any content from the index of that instance to the end of the chunk 
def remove_area_x_from_chunks(still_needed_chunks):
    area_x_removed_chunks_list = []

    for chunk in still_needed_chunks:
        if (match := re.search(r'Area [A-Z]', chunk)):
            chunk = chunk[:chunk.find(match.group())]
        
        area_x_removed_chunks_list.append(chunk)

    return area_x_removed_chunks_list

# Searches each 'Still needed:' chunk for the first occurrence of an instance of 'Major in', then removes
# any content from the index of that instance to the end of the chunk
def remove_major_in_from_chunks(still_needed_chunks):
    major_in_removed_chunks_list = []

    for chunk in still_needed_chunks:
        if (match := re.search(r'Major in', chunk)):
            chunk = chunk[:chunk.find(match.group())]

        major_in_removed_chunks_list.append(chunk)

    return major_in_removed_chunks_list

def remove_minor_in_from_chunks(still_needed_chunks):
    minor_in_removed_chunks_list = []

    for chunk in still_needed_chunks:
        if (match := re.search(r'Minor in', chunk)):
            chunk = chunk[:chunk.find(match.group())]

        minor_in_removed_chunks_list.append(chunk)

    return minor_in_removed_chunks_list

# Removes all 'Still needed:' chunks that only contain a simple deliverable
def remove_simple_deliverable_chunks(still_needed_chunks):
    simple_deliverables_removed_chunks_list = []
    
    for chunk in still_needed_chunks:
        num_letter_blocks = len(re.findall(r'(?:[A-Z]{4}|\s{1,2}@\s{1,2})', chunk))
        num_number_blocks = len(re.findall(r'(?:\d{4}([@A-Z])?|\d@)', chunk))

        if (num_letter_blocks > 1 or num_number_blocks > 1) or ('Credit' in chunk):
            simple_deliverables_removed_chunks_list.append(chunk)

    return simple_deliverables_removed_chunks_list

# Removes after the last instance of a valid course block for each 'Still needed:' chunk
def remove_after_last_course_block(still_needed_chunks):
    still_needed_chunks_after_last_course_block_removed_list = []

    for chunk in still_needed_chunks:
        number_block_matches = list(re.finditer(r'(?:\d{4}([@A-Z])?|\d@)', chunk))

        if number_block_matches:
            still_needed_chunks_after_last_course_block_removed_list.append(chunk[:number_block_matches[-1].end()])

    return still_needed_chunks_after_last_course_block_removed_list

# Removes any new line characters and multiple spaces from a node's name
def remove_newline_multispace_from_string(name_string):
    cleaned_name_string = ''
    newlined_removed_string = name_string.replace('\n', ' ')
    cleaned_name_string = re.sub(' {2,}', ' ', newlined_removed_string)
    return cleaned_name_string

# From a given 'Still needed:' chunk, generates all course and exception blocks and returns as a dictionary
def generate_course_blocks(chunk):
    course_blocks_list = []
    exception_blocks_list = []
    letter_block_regex_pattern = r'(?:[A-Z]{4}|\s{1,2}@\s{1,2})'
    # number_block_regex_pattern = r'(?:\d{4}([@A-Z])?|\d@)'
    number_block_regex_pattern = r'(?:\d{4}([@A-Z])?|\d@[A-Z]?)'
    letter_block_number_block_and_except_regex_pattern = r'(?:[A-Z]{4}|\s{1,2}@\s{1,2})|(?:\d{4}([@A-Z])?|\d@[A-Z]?)|Except'

    # Handle the case of unpredictable numbers of spaces:

    # tokenized list of all number blocks, letter blocks, and the keyword 'except' if it exists
    letter_block_number_block_and_except_list = list(re.finditer(letter_block_number_block_and_except_regex_pattern, chunk))

    # Assume that the first item found in the list will always be a letter block
    current_letter_block = letter_block_number_block_and_except_list[0].group()

    # Boolean for checking if the current letter/number blocks should be considered exceptions
    currently_processing_exceptions = False

    for generalized_block in letter_block_number_block_and_except_list:

        # check if the current item in the list is a letter block
        if (match_obj := re.search(letter_block_regex_pattern, generalized_block.group())): 
            current_letter_block = generalized_block.group()

        # Check if the item in the list is a number block
        elif (match_obj := re.search(number_block_regex_pattern, generalized_block.group())):

            # If a number block is found in the list and the 'Except' keyword has been found, 
            # consider the item an exception
            if currently_processing_exceptions:
                exception_blocks_list.append(f'{current_letter_block} {match_obj.group()}')

            # Otherwise, consider the item a required course
            else:
                course_blocks_list.append(f'{current_letter_block} {match_obj.group()}')
        
        # Check to see if the token is 'Except'. If it is, all following items are exceptions.]
        if(match_obj := re.search('Except', generalized_block.group())):
            currently_processing_exceptions = True

    for item_index, item in enumerate(exception_blocks_list):
        cleaned_item = item.strip().replace('  ', ' ')
        exception_blocks_list[item_index] = cleaned_item

    for item_index, item in enumerate(course_blocks_list):
        cleaned_item = item.strip().replace('  ', ' ')
        course_blocks_list[item_index] = cleaned_item

    course_blocks_and_exceptions_dict = {
        "course_blocks": course_blocks_list,
        "exception_blocks": exception_blocks_list
    }

    return course_blocks_and_exceptions_dict

# Classifies and handles items from a dictionary containing lists of course blocks and exception blocks, 
# returning a part of the complex deliverables string
def classify_and_handle_course_blocks(course_blocks_and_exceptions_dict):
    handled_course_blocks_string = ''
    exception_string = ''
    
    if len(course_blocks_and_exceptions_dict['exception_blocks']) > 0:
        exception_string += '^(?!'
        if len(course_blocks_and_exceptions_dict['exception_blocks']) == 1:
            exception_string += course_blocks_and_exceptions_dict['exception_blocks'][0]
        else:
            exception_string += ('|').join(course_blocks_and_exceptions_dict['exception_blocks'])
        exception_string += ')'
    
    for course_block in course_blocks_and_exceptions_dict["course_blocks"]:

        if (letter_block := course_block.split()[0]) and (number_block := course_block.split()[1]):
            # check for inserter node
            if re.match(r'\d@', number_block):
                if letter_block == '@':
                    handled_course_blocks_string += f'[i <n=Insert {remove_newline_multispace_from_string(course_block)}, ga={course_block} Course, gp={exception_string}[A-Z]{{4}} {number_block[0]}\d{{3}}[A-Z]?>]\n'
                else:
                    handled_course_blocks_string += f'[i <n=Insert {remove_newline_multispace_from_string(course_block)}, ga={course_block} Course, gp={exception_string}{letter_block} {number_block[0]}\d{{3}}[A-Z]?>]\n'
            # check for protocol node
            elif re.match(r'\d{4}@', number_block):
                handled_course_blocks_string += f'[p <n={remove_newline_multispace_from_string(course_block)}, m={course_block[:-1]}.*>]\n'
            # check for deliverable node
            elif re.match(r'\d{4}([A-Z])?$', number_block):
                handled_course_blocks_string += f'[d <n={get_latest_id(remove_newline_multispace_from_string(course_block))}>]\n'
            
            # catch any unhandled nodes
            else:
                print(f'found an unclassified number block')

    return handled_course_blocks_string

def classify_and_handle_chunks(still_needed_chunks):
    """
    Iterates through a list of cleaned 'Still needed:' chunks, classifying each according to its type.
    Then, appends to a complex deliverables string, the string used to create the complex logic tree
    representing all choices the student must make to satisfy the Degreeworks requirements. Returns the
    complex deliverables string after all chunks have been classified, processed, and appended.

    Parameters:
    still_needed_chunks (list): A list of cleaned 'Still needed:' chunks.

    Returns:
    str: A complex deliverables string. See documentation for detailed explanation of complex deliverables strings.

    """

    complex_deliverables_string = ''
    
    for chunk_index, chunk in enumerate(still_needed_chunks):
        
        # Nested shallow selection node
        if (name := re.search(r'Choose from \d{1} of the following:', chunk)):
            required_count = name.group()[name.group().find(' of the following:') - 1]
            complex_deliverables_string += f'[s <c={required_count}, n={remove_newline_multispace_from_string(name.group())}>\n'

            sub_chunk_list = []
            sub_chunk_start_matches_list = list(re.finditer('\d{1,2} Class(es)?|\d{1,2} Credit[s]?', chunk))
            sub_chunk_start_matches_start_index_list = []

            for sub_chunk_start_match in sub_chunk_start_matches_list:
                sub_chunk_start_matches_start_index_list.append(sub_chunk_start_match.start())
            
            if not sub_chunk_start_matches_list:
                print('We have found a special shallow selection node with nothin in it. Error')
            
            for current_index, start_index in enumerate(sub_chunk_start_matches_start_index_list):
                if not current_index + 1 >= len(sub_chunk_start_matches_start_index_list):
                    sub_chunk_list.append(chunk[sub_chunk_start_matches_start_index_list[current_index]:sub_chunk_start_matches_start_index_list[current_index + 1]].strip())
                else:
                    sub_chunk_list.append(chunk[sub_chunk_start_matches_start_index_list[current_index]:])

            complex_deliverables_string += classify_and_handle_chunks(sub_chunk_list)

            complex_deliverables_string += ']\n'
        
        # Normal shallow selection node
        elif (name := re.search(r'\d{1,2} Class(es)? in .*[\s]*(or|and)[\s\n]*', chunk)):
            required_count = re.search(f'\d+(\d+)?', name.group()).group()
            
            name = chunk.replace('  ', ' ')
            
            complex_deliverables_string += f'[s <c={required_count}, n={remove_newline_multispace_from_string(name)}>\n'
            
            course_blocks_and_exceptions_dict = generate_course_blocks(chunk)
            
            complex_deliverables_string += classify_and_handle_course_blocks(course_blocks_and_exceptions_dict)
            
            complex_deliverables_string += ']\n'

        # Deliverable node
        elif not (re.search(r'1 Class in [A-Z]{4} \d{4}[A-Z@]?[\s\n]+or[\s\n]+', chunk)) and re.search(r'1 Class in [A-Z]{4} \d{4}(?:[A-Z](?=[\s\n]))?', chunk):
            required_count = re.search('\d+(\d+)?', chunk).group()
            
            course_blocks_and_exceptions_dict = generate_course_blocks(chunk)
            
            complex_deliverables_string += classify_and_handle_course_blocks(course_blocks_and_exceptions_dict)

        # Deep credit selection node
        elif (match_obj := re.search(r'\d{1,2} Credit[s]? in', chunk)):
            required_count = required_count = re.search('\d+(\d+)?', chunk).group()
            
            name = chunk.replace('  ', ' ')
            
            complex_deliverables_string += f'[r <c={required_count}, n={remove_newline_multispace_from_string(name)}>\n'
            
            course_blocks_and_exceptions_dict = generate_course_blocks(chunk)

            complex_deliverables_string += classify_and_handle_course_blocks(course_blocks_and_exceptions_dict)
            
            complex_deliverables_string += ']\n'
            
        else:
            complex_deliverables_string += ''

    return complex_deliverables_string

def generate_complex_deliverables_string(document_string):
    """
    Generates a complex deliverables string by processing the input document_string, which is an unprocessed
    Degreeworks document string. The complex deliverables string represents all choices the student must make 
    to satisfy the Degreeworks requirements.

    The function performs the following steps:
    1. Removes all currently taken courses.
    2. Splits the document_string into 'Still needed:' chunks.
    3. Removes 'Still needed:' chunks that do not contain any courses.
    4. Removes chunks that do not start with a course.
    5. Removes student information from the chunks.
    6. Removes 'Satisfied by' blocks from the chunks.
    7. Removes 'Area X' blocks from the chunks.
    8. Removes 'Major in' blocks from the chunks.
    9. Removes simple deliverable chunks.
    10. Classifies and handles remaining chunks, appending them to the complex deliverables string.

    Parameters:
    document_string (str): The input document string (the parsed Degreeworks PDF) containing 
    Degreeworks requirements.

    Returns:
    str: A complex deliverables string. See documentation for a detailed explanation of complex 
    deliverables strings.

    """

    complex_deliverables_string = ''

    curr_taken_courses_removed_string = remove_all_curr_taken_courses(document_string)

    still_needed_chunks_list = split_into_still_needed_chunks(curr_taken_courses_removed_string)

    still_needed_chunks_no_course_removed_list = remove_no_course_still_needed_chunks(still_needed_chunks_list)

    still_needed_chunks_starting_with_course_list = remove_chunks_not_starting_with_course(still_needed_chunks_no_course_removed_list)
    
    still_needed_chunks_student_info_removed_list = remove_student_info(still_needed_chunks_starting_with_course_list)
    
    still_needed_chunks_satisfied_by_removed_list = remove_satisfied_by_blocks(still_needed_chunks_student_info_removed_list)
    
    area_x_removed_chunks_list = remove_area_x_from_chunks(still_needed_chunks_satisfied_by_removed_list)
    
    major_in_removed_chunks_list = remove_major_in_from_chunks(area_x_removed_chunks_list)

    minor_inr_removed_chunks_list = remove_minor_in_from_chunks(major_in_removed_chunks_list)
    
    simple_deliverables_removed_chunks_list = remove_simple_deliverable_chunks(minor_inr_removed_chunks_list)
    
    still_needed_chunks_after_last_course_block_removed_list = remove_after_last_course_block(simple_deliverables_removed_chunks_list)

    complex_deliverables_string += classify_and_handle_chunks(still_needed_chunks_after_last_course_block_removed_list)
    
    return complex_deliverables_string

# Generates and returns the courses needed construction string, including both the simple 
# and complex deliverables strings
def generate_courses_needed_construction_string(document_string):
    courses_needed_construction_string = ''

    courses_needed_construction_string += generate_simple_deliverables_string(document_string)

    courses_needed_construction_string += generate_complex_deliverables_string(document_string)

    return courses_needed_construction_string

def generate_degree_extraction_container(file_name):

    """
    Generates a DegreeExtractionContainer object by extracting and processing data from a given 
    Degreeworks PDF file.

    The function performs the following steps:
    1. Reads the PDF file and extracts its text content.
    2. Extracts student information, including: student name, student number, degree plan name, 
    GPA, and current/taken courses.
    3. Generates a courses_needed_construction_string by processing the document_string from the 
    Degreeworks document.
    4. Creates and returns a DegreeExtractionContainer object with the extracted and processed data.

    Parameters:
    file_name (str): The file name (path) of the Degreeworks PDF file to process.

    Returns:
    DegreeExtractionContainer: A DegreeExtractionContainer object containing the processed data 
    from the Degreeworks PDF file.

    """

    with open(file_name, 'rb') as degreeworks_pdf:
        pdf_reader = PdfReader(degreeworks_pdf)

        courses_needed_constuction_string = ''
        document_string = ''
        degree_plan_name = None
        student_number = None
        student_name = None

        curr_taken_courses = []

        for page in range(len(pdf_reader.pages)):
            page_text = pdf_reader.pages[page].extract_text()
            document_string += page_text

        student_name = get_student_name(document_string)
        student_number = get_student_number(document_string)
        degree_plan_name = get_degree_plan_name(document_string)
        gpa = get_gpa(document_string)
        curr_taken_courses = find_curr_taken_courses(document_string)
        courses_needed_constuction_string = generate_courses_needed_construction_string(document_string)

    PDF_to_CBR_Formatter.format_main(file_name, gpa, courses_needed_constuction_string)
    return DegreeExtractionContainer(curr_taken_courses, courses_needed_constuction_string, degree_plan_name, student_number, student_name, gpa)

if __name__ == '__main__':
    container = generate_degree_extraction_container('./src//input_files/updated_degreeworks/S10.pdf')
    print(container)